{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b572b-1fbe-4fcf-9c5c-b8c8f03c747b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "1ccaa4ce-abf5-427c-adf6-8d3fa9d3283f",
       "queued_time": "2025-04-04T12:01:10.1642228Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " pip install requests pytz azure-servicebus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3363921-fc6c-41b7-80a1-401139c373b9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "700940fa-8c8e-4017-a819-d842d7de3f7e",
       "queued_time": "2025-04-04T12:01:10.1708218Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Fetch real-time data from the Weather API\n",
    "    response = requests.get(\"enter your api request key\")\n",
    "    response.raise_for_status()  # Raises an error if the request fails\n",
    "\n",
    "    # Convert the response to JSON format\n",
    "    data = response.json()\n",
    "\n",
    "    # Print the sample API response for verification\n",
    "    #print(\"Sample API Response:\", json.dumps(data, indent=4))\n",
    "\n",
    "    # Function to Flatten JSON and Extract Keys with Values\n",
    "    def flatten_json(nested_json, parent_key=''):\n",
    "        flattened = {}\n",
    "        for key, value in nested_json.items():\n",
    "            new_key = f\"{parent_key}.{key}\" if parent_key else key  # Append parent key for nested items\n",
    "            if isinstance(value, dict):\n",
    "                flattened.update(flatten_json(value, new_key))\n",
    "            else:\n",
    "                flattened[new_key] = value\n",
    "        return flattened\n",
    "\n",
    "    # Extract Column Headers with Values\n",
    "    flattened_data = flatten_json(data)\n",
    "    data=flattened_data\n",
    "\n",
    "    # Print Columns with Values\n",
    "    print(\"\\nExtracted Data (Column Name : Value):\\n\")\n",
    "    for key, value in flattened_data.items():\n",
    "        print(f\"{key} : {value}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071dcda-be44-4647-8a8a-f4bd625b80eb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "03436b62-e90e-4bb9-8205-a6dc9bc46e40",
       "queued_time": "2025-04-04T12:01:10.1726428Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Get the current time in Sydney, Australia\n",
    "sydney_tz = pytz.timezone(\"Europe/London\")\n",
    "now_sydney = datetime.now(sydney_tz)\n",
    "\n",
    "# Format the timestamp in different ways\n",
    "formatted_datetime = now_sydney.strftime(\"%m/%d/%Y %I:%M:%S %p\")  # MM/DD/YYYY HH:MM:SS AM/PM\n",
    "date_column = now_sydney.strftime(\"%d-%m-%Y\")  # DD-MM-YYYY\n",
    "time_column = now_sydney.strftime(\"%H:%M:%S\")  # HH:MM:SS\n",
    "\n",
    "# Check if data is a dictionary (single record) or a list (multiple records)\n",
    "if isinstance(data, dict):\n",
    "    # If it's a single object, update it directly\n",
    "    data[\"datetime\"] = formatted_datetime\n",
    "    data[\"date\"] = date_column\n",
    "    data[\"time\"] = time_column\n",
    "    updated_data = [data]  # Convert to a list for consistent processing\n",
    "else:\n",
    "    # If it's a list, iterate over each record\n",
    "    for record in data:\n",
    "        record[\"datetime\"] = formatted_datetime\n",
    "        record[\"date\"] = date_column\n",
    "        record[\"time\"] = time_column\n",
    "    updated_data = data\n",
    "\n",
    "# Print the updated data structure\n",
    "print(\"Sample Data with Timestamps:\")\n",
    "print(updated_data[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52652b-038f-461c-8ed6-3e1ff02c2fcb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "3c4281f9-3561-4df8-afcd-ddbc12b17dc6",
       "queued_time": "2025-04-04T12:01:10.1787453Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.servicebus import ServiceBusClient, ServiceBusMessage\n",
    "import json\n",
    "\n",
    "# Replace with your Fabric EventStream connection string\n",
    "myconnectionstring = \"eventstream connection string\"\n",
    "\n",
    "# Function to send messages to Fabric EventStream\n",
    "def send_to_eventstream(messages, connection_string):\n",
    "    # Extract EntityPath from connection string (always included)\n",
    "    entity_path = None\n",
    "    for param in connection_string.split(';'):\n",
    "        if param.startswith('EntityPath='):\n",
    "            entity_path = param.split('=')[1]\n",
    "            break\n",
    "\n",
    "    # Ensure EntityPath is found (it should always be included)\n",
    "    if not entity_path:\n",
    "        raise ValueError(\"EntityPath is missing in the connection string. Please check your Fabric setup.\")\n",
    "\n",
    "    # Ensure data is always a list before sending\n",
    "    if isinstance(messages, dict):\n",
    "        messages = [messages]  # Convert single object to a list\n",
    "\n",
    "    # Establish connection to Fabric EventStream\n",
    "    servicebus_client = ServiceBusClient.from_connection_string(connection_string)\n",
    "    try:\n",
    "        with servicebus_client.get_queue_sender(entity_path) as sender:\n",
    "            # Convert messages to JSON format\n",
    "            batch_message = [ServiceBusMessage(json.dumps(msg)) for msg in messages]\n",
    "            sender.send_messages(batch_message)\n",
    "            print(f\"Successfully sent {len(messages)} records to EventStream.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending messages: {e}\")\n",
    "    finally:\n",
    "        servicebus_client.close()\n",
    "\n",
    "send_to_eventstream(data, myconnectionstring)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9e0bd-f579-4459-a23c-0666f77b10d5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e9f59-4307-487e-9a9b-fea1ac2ed432",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "8a8c688c-08b8-4e7a-90ef-ecf9d4f65d8f",
    "default_lakehouse_name": "firstlakehouse",
    "default_lakehouse_workspace_id": "311d52dc-bc19-460c-a265-ff04ac0b6ed3"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "720000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
